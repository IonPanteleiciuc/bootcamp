{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#023F7C> **Data cleaning and exploration** </font>\n",
    "\n",
    "<font color=#023F7C>**Hi! PARIS DataBootcamp 2023 üöÄ**</font> <br>\n",
    "\n",
    "\n",
    "<img src = https://www.hi-paris.fr/wp-content/uploads/2020/09/logo-hi-paris-retina.png width = \"300\" height = \"200\" >\n",
    "\n",
    "**What is Data Cleaning ?**<br>\n",
    "\n",
    "Data cleaning is a crucial step in the data analysis and machine learning process, as the quality of the insights and models generated heavily relies on the accuracy and reliability of the underlying data. Raw data often contains **errors**, **inconsistencies**, **missing values**, and **outliers** that can distort results or lead to faulty conclusions. Data cleaning involves identifying and rectifying these issues, ensuring the dataset is trustworthy and suitable for analysis. \n",
    "\n",
    "Python provides a robust ecosystem of libraries and tools for data cleaning tasks. <br>\n",
    "Python's versatility in data cleaning contributes significantly to producing accurate analyses and reliable machine learning models.\n",
    "- The `Pandas`  library offers functions to handle missing data through imputation or removal, detect and remove duplicates, and transform data types. \n",
    "- The `NumPy` library can assist in dealing with outliers by providing statistical methods for outlier detection and filtering. \n",
    "- Additionally, visualization libraries like Matplotlib and Seaborn can help visually identify anomalies. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you start to working on this notebook ‚ö†Ô∏è**: <br>\n",
    "Please download/copy this notebook from `hfactory_magic_folders\\course` and drop it into your own directory `my_work` on HFactory. <br>\n",
    "If you don't, you won't be able to save the modifications you've made on this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business case** üíº: <br>\n",
    "You've been provided a supply chain dataset by an organization that is trying to improve their supply chain operations.<br>\n",
    "- The goal of the bootcamp is to use Machine Learning to be able to predict either `Late_delivery_risk` or `Delivery_Status` in the dataset. <br>\n",
    "- Before building a Machine Learning model, an essential step is to clean and analyze the data with data visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need help ? üôè** <br>\n",
    "You can go to the Introduction and Intermediate python notebooks to learn how to use the `pandas` library. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV9lJlEhh7EI"
   },
   "source": [
    "## **1. Import libraries and dataset**\n",
    "First, let's import Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "0l0FgH2Dh9WJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "pd.set_option('display.max_columns', None) #Show all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4d6xtYaxmm_"
   },
   "source": [
    "Then, let's import the dataset `dataset_train.csv` using pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RYgbzYVjiDt5"
   },
   "outputs": [],
   "source": [
    "path=r'~/hfactory_magic_folders/course/Dataset/dataset_train.csv'\n",
    "\n",
    "# Import the csv file\n",
    "dataset = pd.read_csv(path,encoding='latin-1',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNUY-ADWh0Wy"
   },
   "source": [
    "## **2. Data discovery**\n",
    "\n",
    "**Question 1**: <br> \n",
    "**Display the dataset's head and tail.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "EVIuGsTniN71",
    "outputId": "aa8adfc7-bfc8-49b9-fcbe-897e1b8ac72d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "YjnXMd9AiSwM",
    "outputId": "760cae6f-c550-4050-a2b0-10d3b9869cef"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRFQab8VzPYM"
   },
   "source": [
    "**Question 2**: <br> **Use the pandas function `.info()` to get general information on the dataset.**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "bkVRhsQp7S8k",
    "outputId": "7f8d0a64-8ffc-4e28-f5da-113b67384e4e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you say about the loaded dataset ?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLifVexBec3l"
   },
   "source": [
    "**Question 3**:  <br> **Print all the columns/variables of the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "seJ0yJoKiQpG",
    "outputId": "d6cd2845-6d78-4f41-826d-58dd146eca05"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1biQZs92inr0"
   },
   "source": [
    "## **3. Analyze the dataframe's dtypes**\n",
    "**Question 4**: <br> \n",
    "**Create 3 lists, each containing columns names with an int, float and object type.**\n",
    "- List 1: Columns with an `int64` type\n",
    "- List 2: Columns with a `float64` type\n",
    "- List 3: Columns with an `object` type.\n",
    "\n",
    "*Note: You can use pandas' `.select_dtypes()` function to get columns with a specific dtype.* <br>\n",
    "*Create a list from a Pandas Dataframe/series with `.to_list()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUzSKfxDiwAr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBjyPD9HetOq"
   },
   "source": [
    "**Question 5**: <br> \n",
    "**Compute the number of unique values for the columns with an object and int type.** <br>\n",
    "\n",
    "*Note: Combine the list with int columns and object columns using the `+` operator*. <br>\n",
    "*Create a dataframe with the number of unique values and the corresponding variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which column/variable has over 15 unique values ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**: <br>\n",
    "**Compute the summary statistics of columns with a float type, with pandas' `.describe()` function.** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you detect outliers (weird/abnormal values) in the data ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Analyze missing values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U82k4QWReiC-"
   },
   "source": [
    "**Question 7**: <br> **Compute the number of NaN value for every variable/column** <br> \n",
    "\n",
    "*Note: A NaN value represents a missing value in a cell of the dataframe* <br>\n",
    "*You can use the `.isna()` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyvZgbQx8Aya",
    "outputId": "c6e9800d-b8c5-4912-ec60-a5669082defa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which variables of the dataset has missing values ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:** <br> \n",
    "**Drop the columns of the dataset that have missing values with `.dropna(axis=1)`. <br>**\n",
    "Don't forget to add `.reset_index(drop=True)` after dropping the NaN values in the dataframe !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you don't want to drop rows, you can replace the missing values in each variable** <br>\n",
    "Try the following methods only if the variable has a small number of NaN values (less than 10%).\n",
    "- Replace with the mean or median value for continuous variables (mostly columns with a float dtype)\n",
    "- Replace with the variable's most frequent value (`.mode()`) or by creating a new category for categorical variables (mostly columns with an int/object dtype)\n",
    "\n",
    "You can drop the variables with a high number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step, the dataset shouldn't have any missing values (you can check with `.isna().sum().sum()`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**: <br>\n",
    "We want to share this dataset with a customer. Can we do this without modifying it? <br>\n",
    "If not, drop the element/variables that we have to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**: <br>\n",
    "**Save the cleaned dataframe as a csv file called `dataset_train_clean.csv` using pandas' `.to_csv()` function.** <br>\n",
    "*Note: Make sure to add `index=False` to the `.to_csv()` function or else the index of the dataframe will be saved too.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
